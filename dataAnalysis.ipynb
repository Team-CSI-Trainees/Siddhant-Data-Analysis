{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18d632e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "df = pd.read_csv(\"Data.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1bee610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92e627d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training and Testing dataset \n",
    "train = df[df['Date'] < '20150101']\n",
    "test = df[df['Date'] > '20141231']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2611a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train.iloc[:,2:27]\n",
    "data.replace(\"[^a-zA-Z]\",\" \",regex=True, inplace=True)\n",
    "\n",
    "list_temp = [i for i in range(25)]\n",
    "new_index = [str(i) for i in list_temp]\n",
    "data.columns = new_index\n",
    "for index in new_index:\n",
    "    data[index]=data[index].str.lower()\n",
    "#data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a8b56a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "#from nltk.tokenize import word_tokenize\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "from string import punctuation\n",
    "punctuation = list(punctuation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94d011d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines=[]\n",
    "# for x in data.iloc[row,0:25]:\n",
    "#         print(x)\n",
    "for row in range(0, len(data.index)):\n",
    "    headlines.append(' '.join(str(x) for x in data.iloc[row, 0:25]))\n",
    "#headlines[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a83f85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for x in range(len(headlines)):\n",
    "    words = nltk.word_tokenize(headlines[x])\n",
    "    wordsFiltered = []\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            wordsFiltered.append(w)\n",
    "    tokens.append(wordsFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07bb3d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3975\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd394d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "newHead = []\n",
    "for x in range(len(tokens)):\n",
    "    newHead.append(TreebankWordDetokenizer().detokenize(tokens[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb9a3f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hindrance operations extracts leaked reports scorecard hughes instant hit buoys blues jack gets skates ice cold alex chaos maracana builds united depleted leicester prevail elliott spoils everton party hungry spurs sense rich pickings gunners wide easy target derby raise glass strupar debut double southgate strikes leeds pay penalty hammers hand robson youthful lesson saints party like wear wolves turned lambs stump mike catches testy gough taunt langer escapes hit flintoff injury piles woe england hunters threaten jospin new battle somme kohl successor drawn scandal difference men women sara denver nurse turned solicitor diana landmine crusade put tories panic yeltsin resignation caught opposition flat footed russian roulette sold recovering title'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newHead[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5dc2df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=200)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## implement BAG OF WORDS\n",
    "countvector=CountVectorizer(ngram_range=(2,2))\n",
    "traindataset=countvector.fit_transform(newHead)\n",
    "\n",
    "# implement RandomForest Classifier\n",
    "randomclassifier=RandomForestClassifier(n_estimators=200,criterion='entropy')\n",
    "randomclassifier.fit(traindataset,train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a45ccdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform= []\n",
    "for row in range(0,len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "test_dataset = countvector.transform(test_transform)\n",
    "predictions = randomclassifier.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e60623e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130  56]\n",
      " [  0 192]]\n",
      "0.8518518518518519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.70      0.82       186\n",
      "           1       0.77      1.00      0.87       192\n",
      "\n",
      "    accuracy                           0.85       378\n",
      "   macro avg       0.89      0.85      0.85       378\n",
      "weighted avg       0.89      0.85      0.85       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "matrix=confusion_matrix(test['Label'],predictions)\n",
    "print(matrix)\n",
    "score=accuracy_score(test['Label'],predictions)\n",
    "print(score)\n",
    "report=classification_report(test['Label'],predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1772427d",
   "metadata": {},
   "source": [
    "TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03ce4f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=200)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## implement BAG OF WORDS\n",
    "tfidfvector=TfidfVectorizer(ngram_range=(2,2))\n",
    "traindataset=tfidfvector.fit_transform(newHead)\n",
    "\n",
    "# implement RandomForest Classifier\n",
    "randomclassifier=RandomForestClassifier(n_estimators=200,criterion='entropy')\n",
    "randomclassifier.fit(traindataset,train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0facadf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform= []\n",
    "for row in range(0,len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "test_dataset = countvector.transform(test_transform)\n",
    "predictions = randomclassifier.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5f91291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[121  65]\n",
      " [ 16 176]]\n",
      "0.7857142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.65      0.75       186\n",
      "           1       0.73      0.92      0.81       192\n",
      "\n",
      "    accuracy                           0.79       378\n",
      "   macro avg       0.81      0.78      0.78       378\n",
      "weighted avg       0.81      0.79      0.78       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "matrix=confusion_matrix(test['Label'],predictions)\n",
    "print(matrix)\n",
    "score=accuracy_score(test['Label'],predictions)\n",
    "print(score)\n",
    "report=classification_report(test['Label'],predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c259f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
